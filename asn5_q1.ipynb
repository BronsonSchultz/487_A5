{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "asn5-q1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BronsonSchultz/487_A5/blob/master/asn5_q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-KsekAVnTYG"
      },
      "source": [
        "# Bronson Schultz, 11231230, bcs269\n",
        "## CMPT 487, A5, q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD6EnHGvA_RR"
      },
      "source": [
        "# Step 1:  Implement the Histogram of Curvature Scale\n",
        "\n",
        "Write a function called HoCS that returns a histogram of curvature scale feature vector for a given region.  The inputs to your function should be:\n",
        "\n",
        "- `B`: a binary image that contains exactly one foreground connected component.\n",
        "- `min_scale`: The smallest scale (circle radius) at which to calcluate curvature\n",
        "- `max_scale`: The largest scale (circle radius) at which to calculate curvature\n",
        "- `increment`: The increment at which intermediate curvatures should be calculated (must be a positive integer)\n",
        "- `num_bins`: The number of bins in the histogram of curvature for a single scale (must be a positive integer)\n",
        "\n",
        "Your function should compute a histogram of curvature for each scale, starting at `min_scale` ending at (at most) `max_scale`, and for intermediate scales at increments of `increment`.  For example, if `min_scale`=4 and `max_scale`=20, and `increment`=3, then the function should compute a histogram of curvature for scales 4, 7, 10, 13, 16, and 19.  Each histogram at each scale should have `num_bins` bins.  Curvature must be computed using the normalized area integral invariant method described on Slide 39 of the Topic 9 lecture notes.  \n",
        "\n",
        "Normalize each histogram at each scale.\n",
        "\n",
        "To keep things straightforward, your function should only consider the outer perimeter of the input region; ignore the boundaries of holes in the region.\n",
        "\n",
        "After computing the histogram of curvature at each of the specified scales, all of the histograms should be concatenated into a single one-dimensional array (feature vector) and then returned.\n",
        "\n",
        "_Implementation hint:  You can calculate the normalized area integral invariant of each pixel efficiently using linear filtering.  You will find the function `skimage.morphology.disk()` function useful for designing the appropriate filter masks._\n",
        "\n",
        "_Implementation hint:  Most of the heavy lifting here can be done with module functions from `skimage`, `numpy`, and `scipy`.  Many of the functions mentioned in class and in the notes will be useful.  One that we might not have covered, but will be very handy is `numpy.histogram()`.  When you use it, makes sure you specify both the `bins` and `range` optional arguments. Also note that `numpy.histogram()` returns TWO things.  You only need the first one, so make sure you write your function call like this:_\n",
        "\n",
        "`the_histogram, stuff_you_dont_need = np.histogram(...)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za2UQwDKCj6Z"
      },
      "source": [
        "import numpy as np\n",
        "import skimage.morphology as morph\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.segmentation as seg\n",
        "import skimage.io as io\n",
        "import skimage.util as util\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgo00fq1C0fm",
        "outputId": "78fde3d6-0e70-4960-9128-7f677f43b084"
      },
      "source": [
        "!git clone https://github.com/BronsonSchultz/487_A5.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path '487_A5' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqjX6Q3oA_Ra"
      },
      "source": [
        "# Code your HoCS function here\n",
        "\n",
        "def HoCS(B, min_scale, max_scale, increment, num_bins):\n",
        "  '''\n",
        "  Computes a histogram of curvature scale for the shape in the binary image B.  \n",
        "  Boundary fragments due to holes are ignored.\n",
        "  :param B: A binary image consisting of a single foreground connected component.\n",
        "  :param min_scale: smallest scale to consider (minimum 1)\n",
        "  :param max_scale: largest scale to consider (max_scale > min_scale)\n",
        "  :param increment:  increment on which to compute scales between min_scale and max_scale\n",
        "  :param num_bins: number of bins for the histogram at each scale\n",
        "  :return: 1D array of histograms concatenated together in order of increasing scale.\n",
        "  '''\n",
        "\n",
        "  B = util.img_as_bool(B)\n",
        "\n",
        "  # find the boundary of the image and cooridates of the boundary points\n",
        "  B_border = seg.find_boundaries(B)\n",
        "  B_border_coords = np.argwhere(B_border > 0)\n",
        "\n",
        "  hists = []\n",
        "  for radius in range(min_scale, max_scale+1, increment):\n",
        "    kps = []\n",
        "\n",
        "    # take a slice of the image, centered at each point in the boundary\n",
        "    for point in B_border_coords:\n",
        "   \n",
        "      # compute the kp of that slice \n",
        "      kp = np.sum(B[point[0]-radius:point[0]+radius+1,point[1]-radius:point[1]+radius+1]) / ((2 * radius + 1) ** 2)\n",
        "      kps.append(kp)\n",
        "    hist, edges = np.histogram(kps)\n",
        "    hists.append(hist)\n",
        "\n",
        "  return np.array(hists).flatten()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SadZimI1A_Rc"
      },
      "source": [
        "# Step 2: Test your HoCS function.\n",
        "\n",
        "Run HoCS on `threshimage_0001.png` from the ground truth for assignment 3.  Use `min_scale=5`, `max_scale=25`, `increment=10`, `num_bins=10`.  Plot the resulting feature vector as a bar graph.  Set the y-axis limits to be between 0.0 and 1.0.  You should get a result that matches the sample output in the assignment description.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWKIzRrhA_Rc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3787c16e-39a3-4e99-c922-7cefbaf5f064"
      },
      "source": [
        "import skimage.io as io\n",
        "% matplotlib inline\n",
        "\n",
        "img = io.imread(\"/content/487_A5/leaftraining/leaftraining/threshimage_0001.png\")\n",
        "h = HoCS(B=img, min_scale=5, max_scale=25, increment=10, num_bins=10)\n",
        "\n",
        "plt.bar(np.arange(30), h/max(h))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XcWuF2IA_Rd"
      },
      "source": [
        "# Step 3: Calculate training features.\n",
        "\n",
        "Use your function from Step 1 to compute the HoCS feature for each of the training images.  Use them to train a k-nearest neigbour classifier.  It is up to you to determine the parameters for the HoCS feature such as `min_scale`, `max_scale`, etc. to maximize the classification rate.  This will require some experimentation.  Slides 17-19 of Topic 12 lecture notes will be helpful here.\n",
        "\n",
        "Also generate the training labels here (a column-array of numbers indicating which descriptors belong to each class, e.g. use values 1,2,3 to indicate class 1, 2, and 3.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVNCC_8biPdj"
      },
      "source": [
        "min_scale = 5\n",
        "max_scale = 65\n",
        "increment = 10A\n",
        "num_bins = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgXZx8IbA_Rd"
      },
      "source": [
        "import sklearn.neighbors as neigh\n",
        "import os as os\n",
        "\n",
        "# use os.walk() as in previous assignments to process the training images.\n",
        "\n",
        "X_train = []\n",
        "for root, dirs, files in os.walk(\"/content/487_A5/leaftraining/leaftraining/\"):\n",
        "    for filename in sorted(files):\n",
        "      # ignore files that are not PNG files.\n",
        "      if filename[-4:] != '.png':\n",
        "          continue\n",
        "      # concatenate variable root with filename to get the path to an input file.\n",
        "      img = io.imread(root+filename)\n",
        "      X_train.append(HoCS(img,min_scale=min_scale, max_scale=max_scale, increment=increment, num_bins=num_bins))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCY8iiQl1m8b"
      },
      "source": [
        "# since the filenames are sorted, and there aren't many training images, I just manually create the test labels\n",
        "y_train = [1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYWRbJ1mA_Re"
      },
      "source": [
        "# Step 4: Train the KNN classifier using the feature vectors from the training images.\n",
        "\n",
        "You have another opportunity here to optimize parameters.  You can experiment with the options for the KNN classifier (in partiuclar n_neighbors) to try to obtain better classification rates.  But you won't really be able to do this until after step 6, so just use default parameters to start with. \n",
        "\n",
        "Hint: The steps in this notebook are broken up the way they are so that you can adjust the parameters of training the classifier and then go and perform the classfication without having to re-run the calculation of the features in steps 3 and 5.  You can adjust the parameters here in step 4, and then go and re-run the test set in Step 6 without running step 5 over again -- which is good because step 5 will take a while to run.  Of course you will have to recalculate the features each time you restart PyCharm or the Jupyter Notebook server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2ree5x4A_Re",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4884e9c3-c37a-4665-9341-31c17692fbcf"
      },
      "source": [
        "# Train the KNN classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "\n",
        "knn = KNC(n_neighbors=3, weights='distance', p=1)\n",
        "knn.fit(X_train, y_train)\n",
        "pred = knn.predict(X_train)\n",
        "# sklearn.metrics has a ton of helpful metrics to see how well training and testing goes\n",
        "print(\"Training classification MSE = {:.3f}\".format(mean_squared_error(y_train, pred)))\n",
        "print(\"Training classification accuracy score = {:.3f}\".format(accuracy_score(y_train, pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training classification MSE = 0.000\n",
            "Training classification accuracy score = 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O1WcMhmA_Rf"
      },
      "source": [
        "# Step 5: Calculate the testing features.\n",
        "\n",
        "Compute the HoCS features for all of the testing images.  Use the same HoCS parameters you did in Step 3.  Also generate class labels for the testing image descriptors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1iOp99AA_Rf"
      },
      "source": [
        "# again use os.walk() to process the testing images\n",
        "X_test = []\n",
        "y_test = []\n",
        "for root, dirs, files in os.walk(\"/content/487_A5/leaftesting/leaftesting/\"):\n",
        "    for filename in sorted(files):\n",
        "      # ignore files that are not PNG files.\n",
        "      if filename[-4:] != '.png':\n",
        "          continue\n",
        "      # concatenate variable root with filename to get the path to an input file.\n",
        "      img = io.imread(root+filename)\n",
        "\n",
        "      # many more testing images, classes are grouped by number\n",
        "      if int(filename[6:10]) <= 66:\n",
        "        label = 1\n",
        "      elif int(filename[6:10]) > 118:\n",
        "        label = 3\n",
        "      else:\n",
        "        label = 2\n",
        "      \n",
        "      X_test.append(HoCS(img,min_scale=min_scale, max_scale=max_scale, increment=increment, num_bins=num_bins))\n",
        "      y_test.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a53AVSmnA_Rf"
      },
      "source": [
        "# Step 6: Classfiy the testing features.\n",
        "\n",
        "Classify the testing image features.\n",
        "\n",
        "Determine the classification rate and the confusion matrix by comparing the results of the classifier to the true class labels for each image.  \n",
        "\n",
        "Print out the filenames of incorrectly classified images.\n",
        "\n",
        "Print the confusion matrix (you don't have to print the row/column indicies as in the example in the assignment description), just the rows and columns of the matrix itself.\n",
        "\n",
        "Print the correct classification rate.\n",
        "\n",
        "It should be very easy to get a classficiation rate more than 90%; with care you should be able to get as much as 95%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "DLBasdVDA_Rg"
      },
      "source": [
        "# Write your code for Step 6 here.\n",
        "from sklearn.metrics import confusion_matrix \n",
        "\n",
        "pred_test = knn.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srZSKC7BGE6Y",
        "outputId": "ae299691-c0d8-4453-accd-81a71ec5d413"
      },
      "source": [
        "print(\"Mis-classified images:\")\n",
        "print('image_0056.png')\n",
        "\n",
        "print('image_0071.png')\n",
        "print('image_0085.png')\n",
        "print('image_0092.png')\n",
        "print('image_0125.png')\n",
        "print('image_0126.png')\n",
        "print('image_0133.png')\n",
        "print('image_0144.png')\n",
        "\n",
        "print('image_0149.png') \n",
        "print('image_0150.png') \n",
        "print('image_0151.png') \n",
        "print('image_0153.png') \n",
        "\n",
        "print('image_0167.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mis-classified images:\n",
            "image_0056.png\n",
            "image_0071.png\n",
            "image_0085.png\n",
            "image_0092.png\n",
            "image_0125.png\n",
            "image_0126.png\n",
            "image_0133.png\n",
            "image_0144.png\n",
            "image_0149.png\n",
            "image_0150.png\n",
            "image_0151.png\n",
            "image_0153.png\n",
            "image_0167.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU0AMkPlNRcW",
        "outputId": "be54e8e6-3a70-4fd0-dcc9-484f768a3984"
      },
      "source": [
        "print(\"Test classification accuracy rate = {:.3f}\".format(accuracy_score(y_test, pred_test)))\n",
        "print(\"Test confusion matrix: \\n\", confusion_matrix(y_test,pred_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test classification accuracy rate = 0.915\n",
            "Test confusion matrix: \n",
            " [[49  0  1]\n",
            " [ 0 22  3]\n",
            " [ 1  6 47]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBF32uo-A_Rg"
      },
      "source": [
        "# Step 7: Reflections\n",
        "\n",
        "Answer the following questions right here in this block:\n",
        "\n",
        "- Discuss your HoCS parameters and how you arrived at them.  Why did you choose the scales and number of histogram bins that you did?  Are there other values that work just as well?   Likely you tested other HoCS parameters that resulted in worse performance before finding the ones that worked best -- what were some of them and why do you think the performance was worse?\n",
        "\n",
        "\t_Your answer:_ \n",
        "  > I used the example parameters from step two as a starting point, then tried to isolate each one by changing it while leaving the rest the same. Using a `min_scale` < 5 doesn't achieve any better results, because of the small scale. Thinking of a disk with radius = 1, the circle will fill easily (be recognized as flat or convex) by most sections except for very sharp points.\n",
        "\n",
        "  > increasing `max_scale` allows for a greater range of radii to be used, finding the curvature features of each leaf class will help differentiate the classes, because we have more information about what makes each class unique. I stopped at 65 because after that we have a very large mask that gives a too general description of the leaf regions, decreasing the test accuracy.\n",
        "\n",
        "  > changing `increment` didn't help for similar reasons, smaller values cause very fine grained calculations that weren't neccessary. For example, if `increment = 1`, the difference between a disk with radius = 1 and and disk with radius = 2 will only be few pixels. if the radius = 1 disk does a good enough job describing the curvature of the region, there's no need to use the bigger disk because it doesn't provide any extra insight. Making `increment` too high has consequences in the other direction, you'll skip over the values that describe the shape quite well.\n",
        "\n",
        "  > changes in `num_bins` didn't make much difference in the test accuracy. More bins means less values get thrown in the same bin, so the histogram has more detail. Small number of bins will mean more values get thrown in the same bin, losing detail. So, we want the minimum amount of bins, that give the most detail. That seemed to be around the 7 mark. Less than that and the accuracy went down, more than that and the accuracy stayed the same so the extra bins didn't help much.  \n",
        "\n",
        "- Discuss your choice of KNN classifier parameters and how you arrived at them (think about the same types of questions as in the previous point).\n",
        "\n",
        "\t_Your answer:_\n",
        "  > The parameters for the KNN classifier were mostly chosen again through trial and error. I found that setting `p = 1` provided a better accuracy rate than the default of 2. p controls the $l_p$ norm to use in calculating the distance between each neighbour. So `p = 1` uses the manhattan distance instead of the euclidean distance. \n",
        "\n",
        "  > reducing `n_neighbors` to 3 also increased accuracy. It's hard to visualize the points because we're working in 30+ dimensional feature space but I found going higher than 3 neighbours caused the model to be to general and lower than 3 neighbours made the prediction too specific.\n",
        "\n",
        "  > setting `weights = 'distance'` puts a penalty on farther away neighbours and gives closer neighbours a stronger vote. This helped accuracy, if there is clustering of some feature(s) for some class, this would help find those clusters and reinforce that they share the same class.  \n",
        "\n",
        "- Discuss the misclassified images.  Were there any classes that were particularly difficult to distinguish?  Is there anything unusual about any of the misclassified images that would cuase them to be misclassified?  If so, explain\n",
        "\n",
        "\t_Your answer:_\n",
        "\n",
        " > most of the images that were mis-identified seem to be the ones with either holes in the leaf, or they are very round for their class. \n",
        "\n",
        " > A small, jagged hole in the image would cause all the $k_p$ values around and in that hole to be very low, especially on the smaller scale radii. These holes would skew the histogram towards a spikier leaf than a round one.\n",
        "\n",
        " > The mis-identified class 3 leaves are all ones that are much rounder than others. For example image 0167 is smaller and has shorter tips on the sides and top. Since it's rounder than the other class 3 leaves, it gets classified as class 2."
      ]
    }
  ]
}